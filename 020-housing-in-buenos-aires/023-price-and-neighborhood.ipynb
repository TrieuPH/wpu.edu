{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.1: Use glob to create a list that contains the filenames for all the Buenos Aires real estate CSV files in the data directory. \n",
    "# Assign this list to the variable name files.\n",
    "from glob import glob\n",
    "files = glob(\"./data/buenos-aires-real-estate-[1-5].csv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.2: Use your wrangle function in a for loop to create a list named frames. \n",
    "# The list should the cleaned DataFrames created from the CSV filenames your collected in files.\n",
    "frames = []\n",
    "for file in files:\n",
    "    df = wrangle(file)\n",
    "    frames.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.3: Use pd.concat to concatenate the items in frames into a single DataFrame df. \n",
    "# Make sure you set the ignore_index argument to True.\n",
    "\n",
    "df = pd.concat(frames, ignore_index = True)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.4: Modify your wrangle function to create a new feature \"neighborhood\". \n",
    "# You can find the neighborhood for each property in the \"place_with_parent_names\" column. \n",
    "# For example, a property with the place name \"|Argentina|Capital Federal|Palermo|\" is located in the neighborhood is \"Palermo\". \n",
    "# Also, your function should drop the \"place_with_parent_names\" column.\n",
    "\n",
    "def wrangle(filepath):\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Subset data: Apartments in \"Capital Federal\", less than 400,000\n",
    "    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
    "    mask_apt = df[\"property_type\"] == \"apartment\"\n",
    "    mask_price = df[\"price_aprox_usd\"] < 400_000\n",
    "    df = df[mask_ba & mask_apt & mask_price]\n",
    "\n",
    "    # Subset data: Remove outliers for \"surface_covered_in_m2\"\n",
    "    low, high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n",
    "    mask_area = df[\"surface_covered_in_m2\"].between(low, high)\n",
    "    df = df[mask_area]\n",
    "\n",
    "    # Split \"lat-lon\" column\n",
    "    df[[\"lat\", \"lon\"]] = df[\"lat-lon\"].str.split(\",\", expand=True).astype(float)\n",
    "    df.drop(columns=\"lat-lon\", inplace=True)\n",
    "\n",
    "    # Extract neighborhood\n",
    "    df[\"neighborhood\"] = df[\"place_with_parent_names\"].str.split(\"|\",expand=True)[3]\n",
    "    df.drop(columns=\"place_with_parent_names\",inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.5: Create your feature matrix X_train and target vector y_train. \n",
    "# X_train should contain one feature: \"neighborhood\". Your target is \"price_aprox_usd\". \n",
    "\n",
    "target = \"price_aprox_usd\"\n",
    "features = [\"neighborhood\"]\n",
    "y_train = df[target]\n",
    "X_train = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.6: Calculate the baseline mean absolute error for your model.\n",
    "\n",
    "y_mean = y_train.mean()\n",
    "y_pred_baseline =  [y_mean] * len(y_train)\n",
    "print(\"Mean apt price:\", y_mean)\n",
    "\n",
    "print(\"Baseline MAE:\", y_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.7: First, instantiate a OneHotEncoder named ohe. Make sure to set the use_cat_names argument to True. Next, fit your transformer to the feature matrix X_train. Finally, use your encoder to transform the feature matrix X_train, and assign the transformed data to the variable XT_train.\n",
    "\n",
    "# Instantiate\n",
    "ohe = OneHotEncoder(use_cat_names=True)\n",
    "# Fit\n",
    "ohe.fit(X_train)\n",
    "# Transform\n",
    "XT_train = ohe.transform(X_train)\n",
    "print(XT_train.shape)\n",
    "XT_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.8: Create a pipeline named model that contains a OneHotEncoder transformer and a LinearRegression predictor. Then fit your model to the training data. \n",
    "\n",
    "model =  make_pipeline(\n",
    "    OneHotEncoder(use_cat_names=True),\n",
    "    LinearRegression()\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.9: First, create a list of predictions for the observations in your feature matrix X_train. Name this list y_pred_training. Then calculate the training mean absolute error for your predictions in y_pred_training as compared to the true targets in y_train.\n",
    "\n",
    "y_pred_training = model.predict(X_train)\n",
    "mae_training = mean_absolute_error(y_pred_training,y_train)\n",
    "print(\"Training MAE:\", round(mae_training, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.10: Run the code below to import your test data buenos-aires-test-features.csv into a DataFrame and generate a Series of predictions using your model. \n",
    "# Then run the following cell to submit your predictions to the grader.\n",
    "\n",
    "X_test = pd.read_csv(\"data/buenos-aires-test-features.csv\")[features]\n",
    "y_pred_test = pd.Series(model.predict(X_test))\n",
    "y_pred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.11: Extract the intercept and coefficients for your model.\n",
    "\n",
    "intercept = model.named_steps[\"linearregression\"].intercept_\n",
    "coefficients = model.named_steps[\"linearregression\"].coef_\n",
    "print(\"coefficients len:\", len(coefficients))\n",
    "print(coefficients[:5])  # First five coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.12: Extract the feature names of your encoded data from the OneHotEncoder in your model.\n",
    "\n",
    "feature_names = model.named_steps[\"onehotencoder\"].get_feature_names()\n",
    "print(\"features len:\", len(feature_names))\n",
    "print(feature_names[:5])  # First five feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.13: Create a pandas Series named feat_imp where the index is your features and the values are your coefficients.\n",
    "\n",
    "feat_imp = pd.Series(coefficients, index= feature_names)\n",
    "feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.14: Run the cell below to print the equation that your model has determined for predicting apartment price based on longitude and latitude\n",
    "\n",
    "print(f\"price = {intercept.round(2)}\")\n",
    "for f, c in feat_imp.items():\n",
    "    print(f\"+ ({round(c, 2)} * {f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.15: Scroll up, change the predictor in your model to Ridge, and retrain it. \n",
    "# Then evaluate the model's training and test performance. Do you still have an overfitting problem? If not, extract the intercept and coefficients again (you'll need to change your code a little bit) and regenerate the model's equation. \n",
    "# Does it look different than before?\n",
    "\n",
    "# change in 2.3.8\n",
    "\n",
    "model =  make_pipeline(\n",
    "    OneHotEncoder(use_cat_names=True),\n",
    "    Ridge()\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.16: Create a horizontal bar chart that shows the top 15 coefficients for your model, based on their absolute value.\n",
    "\n",
    "feat_imp.sort_values(key=abs).tail(15).plot(kind=\"barh\")\n",
    "plt.xlabel(\"Importance [USD]\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance for Apartment Price\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f2380935a852bfd6cd376048d8438f0291ac020ced12a3def74eecbc5a3998c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
