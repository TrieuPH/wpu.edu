{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'], ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'], ['Milk', 'Apple', 'Kidney Beans', 'Eggs'], ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'], ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n",
      "              antecedents            consequents  antecedent support  \\\n",
      "0                  (Eggs)         (Kidney Beans)                 0.8   \n",
      "1          (Kidney Beans)                 (Eggs)                 1.0   \n",
      "2                  (Eggs)                (Onion)                 0.8   \n",
      "3                 (Onion)                 (Eggs)                 0.6   \n",
      "4                  (Milk)         (Kidney Beans)                 0.6   \n",
      "5                 (Onion)         (Kidney Beans)                 0.6   \n",
      "6                (Yogurt)         (Kidney Beans)                 0.6   \n",
      "7    (Eggs, Kidney Beans)                (Onion)                 0.8   \n",
      "8           (Eggs, Onion)         (Kidney Beans)                 0.6   \n",
      "9   (Kidney Beans, Onion)                 (Eggs)                 0.6   \n",
      "10                 (Eggs)  (Kidney Beans, Onion)                 0.8   \n",
      "11                (Onion)   (Eggs, Kidney Beans)                 0.6   \n",
      "\n",
      "    consequent support  support  confidence  lift  leverage  conviction  \n",
      "0                  1.0      0.8        1.00  1.00      0.00         inf  \n",
      "1                  0.8      0.8        0.80  1.00      0.00         1.0  \n",
      "2                  0.6      0.6        0.75  1.25      0.12         1.6  \n",
      "3                  0.8      0.6        1.00  1.25      0.12         inf  \n",
      "4                  1.0      0.6        1.00  1.00      0.00         inf  \n",
      "5                  1.0      0.6        1.00  1.00      0.00         inf  \n",
      "6                  1.0      0.6        1.00  1.00      0.00         inf  \n",
      "7                  0.6      0.6        0.75  1.25      0.12         1.6  \n",
      "8                  1.0      0.6        1.00  1.00      0.00         inf  \n",
      "9                  0.8      0.6        1.00  1.25      0.12         inf  \n",
      "10                 0.6      0.6        0.75  1.25      0.12         1.6  \n",
      "11                 0.8      0.6        1.00  1.25      0.12         inf  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Sample data\n",
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n",
    "\n",
    "# Transform data into suitable format\n",
    "print(dataset)\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.6, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after remove transaction only one item: \n",
      "                  InvoiceID        Barcode\n",
      "1       VN0001010102230002  2010902000198\n",
      "2       VN0001010102230002  8935049510864\n",
      "3       VN0001010102230002  2602010136625\n",
      "4       VN0001010102230003  2010809000253\n",
      "5       VN0001010102230003  2701020000046\n",
      "...                    ...            ...\n",
      "151930  VN9996020102230158  8858223013039\n",
      "151931  VN9996020102230158  4897036691342\n",
      "151932  VN9996020102230159  8934588063053\n",
      "151933  VN9996020102230159  2270102000033\n",
      "151934  VN9996020102230159  2703010000043\n",
      "\n",
      "[119428 rows x 2 columns]\n",
      "Dataset group Barcode to one transaction: \n",
      "                 InvoiceID                                      Barcode\n",
      "0      VN0001010102230002  2010902000198, 8935049510864, 2602010136625\n",
      "1      VN0001010102230003                 2010809000253, 2701020000046\n",
      "2      VN0001010102230005                 8935001282266, 8936034875357\n",
      "3      VN0001010102230006                  769828221591, 2010805000363\n",
      "4      VN0001010102230007                  810051801514, 2601010000165\n",
      "...                   ...                                          ...\n",
      "38616  VN9996020102230153                 8934564600357, 2010803000112\n",
      "38617  VN9996020102230155  8935049510673, 2010904000028, 8936127791113\n",
      "38618  VN9996020102230156                 8934588063053, 8936079140076\n",
      "38619  VN9996020102230158                 8858223013039, 4897036691342\n",
      "38620  VN9996020102230159  8934588063053, 2270102000033, 2703010000043\n",
      "\n",
      "[38621 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# 1. support(A⇒ B) =P(A ∪ B)\n",
    "\n",
    "# Support (Books) = Freq (Books)/Total transactions made\n",
    "\n",
    "# Support (Books) = 6/100 = 0.06%\n",
    "\n",
    "# 2. Confidence: It is the ratio of combined transactions to individual transactions.\n",
    "\n",
    "# confidence(A⇒ B) =P(B|A)\n",
    "\n",
    "# Confidence (Books) = Combined transactions/Individual transaction\n",
    "\n",
    "# Confidence (Books) = 0.06/0.08 = 0.75\n",
    "\n",
    "# 3. Lift: It is the ratio of the confidence percent to the support percent.\n",
    "\n",
    "# Lift = 0.75/0.10 = 7.5\n",
    "\n",
    "# If the value of lift < 1, the combination is not bought by consumers frequently.\n",
    "# If the value of lift >1, the combination is brought frequently by the consumers.\n",
    "# If the value of lift = 1, then the purchase of antecedent makes no difference on the consequent.\n",
    "\n",
    "# Sample data\n",
    "df1 = pd.read_csv('data.csv')\n",
    "print(df)\n",
    "\n",
    "# Get data from Invoice ID with Barcode\n",
    "dataset = df1[['InvoiceID','Barcode']]#\n",
    "#print(dataset)\n",
    "dataset = dataset[dataset.groupby('InvoiceID')['Barcode'].transform('size') > 1]\n",
    "print(\"Dataset after remove transaction only one item: \\n\", dataset)\n",
    "dataset_str = dataset\n",
    "dataset_str['Barcode'] = dataset_str['Barcode'].astype(str)\n",
    "dataset_str = dataset_str.groupby('InvoiceID')['Barcode'].agg(lambda x: ', '.join(x)).reset_index()\n",
    "print(\"Dataset group Barcode to one transaction: \\n\", dataset_str)\n",
    "\n",
    "dataset_str.to_csv(\"output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
